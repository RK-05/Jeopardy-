{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "“Jeopardy!”.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVbGGPlUYpJdo/FjYUfys6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b755d1b00efe487bab7f9aa2be69c013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f1b86de3a3a9431c8f63d3da0b4c2ed0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b392d3c17ba47daade4f41099656559",
              "IPY_MODEL_ec8dde436e2b48cc8b5eeefa7034b73d"
            ]
          }
        },
        "f1b86de3a3a9431c8f63d3da0b4c2ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b392d3c17ba47daade4f41099656559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce07fc77daa347ea8df4da3f114d52a8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88690a950a384f3b93d445231b2308b0"
          }
        },
        "ec8dde436e2b48cc8b5eeefa7034b73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aec6d3a8303042039cba9277cf3872d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 52.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68bcfb19843d4fd595db742e0f69401a"
          }
        },
        "ce07fc77daa347ea8df4da3f114d52a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88690a950a384f3b93d445231b2308b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aec6d3a8303042039cba9277cf3872d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68bcfb19843d4fd595db742e0f69401a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d87d7f7a2cf47f092546c3bc5b52a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3bad20b4b9c40c18c8a90b514a07ea3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b18d602c077f462c831f05e04ac0d541",
              "IPY_MODEL_0f672d362cbf440ea8a878d22dc4b808"
            ]
          }
        },
        "f3bad20b4b9c40c18c8a90b514a07ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b18d602c077f462c831f05e04ac0d541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_efd361e5779f48758a8bb33cdeb71fc2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6557effeb7443de98a141ee8608acdd"
          }
        },
        "0f672d362cbf440ea8a878d22dc4b808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6507e73b475b4af892f205657fa3cd64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.40MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfe28b387c324dbc8d1ced138931f7b6"
          }
        },
        "efd361e5779f48758a8bb33cdeb71fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6557effeb7443de98a141ee8608acdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6507e73b475b4af892f205657fa3cd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfe28b387c324dbc8d1ced138931f7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "555be67bd1f24b1b95157bfde8dfe6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a9a83b76c8a4d3d9bb02897eb4f692d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cc3688f1d124b5cbecf0c82d3be9c52",
              "IPY_MODEL_1ef053eb312547e2a9f4aeeabce6d30b"
            ]
          }
        },
        "2a9a83b76c8a4d3d9bb02897eb4f692d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cc3688f1d124b5cbecf0c82d3be9c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_90e5d5c6822244eb80354bdbbfbe523f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98e38f0bbbb64a8eb78e55b6fbab4441"
          }
        },
        "1ef053eb312547e2a9f4aeeabce6d30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b24fc23ad8c5476a8b6c393ed27a9e9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:07&lt;00:00, 59.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdeaeb02e8e54717b3e9556caaa98ac9"
          }
        },
        "90e5d5c6822244eb80354bdbbfbe523f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98e38f0bbbb64a8eb78e55b6fbab4441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b24fc23ad8c5476a8b6c393ed27a9e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdeaeb02e8e54717b3e9556caaa98ac9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70655e3609784ccb8f1516245da389ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a6413ae0cc104c34a9e382c7c1893c2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a81b3d881679403099d7033aef826f90",
              "IPY_MODEL_d609a50fefba487fb7a944e460e8f880"
            ]
          }
        },
        "a6413ae0cc104c34a9e382c7c1893c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a81b3d881679403099d7033aef826f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_23127995085043a5a0c2b11798dc4d4f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27aa57e092494a1b9dd67e429c3021a7"
          }
        },
        "d609a50fefba487fb7a944e460e8f880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74bb098ad5cb42b98b884da5911768f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 57.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7500317d5ae4ca99d1b69e0a9bda0cc"
          }
        },
        "23127995085043a5a0c2b11798dc4d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27aa57e092494a1b9dd67e429c3021a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74bb098ad5cb42b98b884da5911768f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7500317d5ae4ca99d1b69e0a9bda0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RK-05/Jeopardy-/blob/main/%E2%80%9CJeopardy!%E2%80%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lWoMfx1fl5N",
        "outputId": "f5aa51d5-08e7-4980-c8e5-a1cfb8e59368"
      },
      "source": [
        "!unzip archive.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  archive.zip\n",
            "  inflating: JEOPARDY_CSV.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs_rxrm3HVt4"
      },
      "source": [
        "!pip install flair\r\n",
        "from flair.embeddings import WordEmbeddings , StackedEmbeddings , DocumentPoolEmbeddings\r\n",
        "from flair.data import Sentence\r\n",
        "from flair.embeddings import TransformerDocumentEmbeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erpGCZkpq7H2"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense ,Dropout , Conv2D,Conv1D , Flatten , Embedding , MaxPool2D , LSTM,GlobalMaxPooling1D, MaxPool1D\r\n",
        "from keras.callbacks import EarlyStopping , ModelCheckpoint , ReduceLROnPlateau\r\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5NcXBhAzQi8"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "j3UMCgykzVFp",
        "outputId": "fb8b16f5-cd80-440e-b59f-0cb4dc651cad"
      },
      "source": [
        "df = pd.read_csv('JEOPARDY_CSV.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Show Number</th>\n",
              "      <th>Air Date</th>\n",
              "      <th>Round</th>\n",
              "      <th>Category</th>\n",
              "      <th>Value</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>HISTORY</td>\n",
              "      <td>$200</td>\n",
              "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
              "      <td>Copernicus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
              "      <td>$200</td>\n",
              "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
              "      <td>Jim Thorpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
              "      <td>$200</td>\n",
              "      <td>The city of Yuma in this state has a record av...</td>\n",
              "      <td>Arizona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>THE COMPANY LINE</td>\n",
              "      <td>$200</td>\n",
              "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
              "      <td>McDonald's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
              "      <td>$200</td>\n",
              "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
              "      <td>John Adams</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Show Number  ...      Answer\n",
              "0         4680  ...  Copernicus\n",
              "1         4680  ...  Jim Thorpe\n",
              "2         4680  ...     Arizona\n",
              "3         4680  ...  McDonald's\n",
              "4         4680  ...  John Adams\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYESi1QG229d",
        "outputId": "6446ce88-c0d4-40ca-a801-904a39ad3a4e"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Show Number    0\n",
              " Air Date      0\n",
              " Round         0\n",
              " Category      0\n",
              " Value         0\n",
              " Question      0\n",
              " Answer        2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFDubqy-zcyo",
        "outputId": "498656a7-77b2-48ed-88a9-9c2a5a78a103"
      },
      "source": [
        "len(df[' Value'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "uTzFEEov8TcD",
        "outputId": "6e0cdfea-933e-49cf-9518-d98fe4c09084"
      },
      "source": [
        "df[df[' Value']=='None']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Show Number</th>\n",
              "      <th>Air Date</th>\n",
              "      <th>Round</th>\n",
              "      <th>Category</th>\n",
              "      <th>Value</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>THE SOLAR SYSTEM</td>\n",
              "      <td>None</td>\n",
              "      <td>Objects that pass closer to the sun than Mercu...</td>\n",
              "      <td>Icarus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>5957</td>\n",
              "      <td>2010-07-06</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>HISTORIC WOMEN</td>\n",
              "      <td>None</td>\n",
              "      <td>She was born in Virginia around 1596 &amp; died in...</td>\n",
              "      <td>Pocahontas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>3751</td>\n",
              "      <td>2000-12-18</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>SPORTS LEGENDS</td>\n",
              "      <td>None</td>\n",
              "      <td>If Joe DiMaggio's hitting streak had gone one ...</td>\n",
              "      <td>H.J. Heinz (Heinz 57 Varieties)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>3673</td>\n",
              "      <td>2000-07-19</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>THE MAP OF EUROPE</td>\n",
              "      <td>None</td>\n",
              "      <td>Bordering Italy, Austria, Hungary &amp; Croatia, i...</td>\n",
              "      <td>Slovenia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>4931</td>\n",
              "      <td>2006-02-06</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>FAMOUS SHIPS</td>\n",
              "      <td>None</td>\n",
              "      <td>On December 27, 1831 it departed Plymouth, Eng...</td>\n",
              "      <td>the HMS Beagle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216686</th>\n",
              "      <td>3940</td>\n",
              "      <td>2001-10-19</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>MAJOR LEAGUE BASEBALL TEAM NAMES</td>\n",
              "      <td>None</td>\n",
              "      <td>This team received its name after an 1890 inci...</td>\n",
              "      <td>Pittsburgh Pirates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216746</th>\n",
              "      <td>6044</td>\n",
              "      <td>2010-12-16</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>SKYSCRAPERS</td>\n",
              "      <td>None</td>\n",
              "      <td>After a construction boom fueled by oil &amp; gas ...</td>\n",
              "      <td>Moscow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216807</th>\n",
              "      <td>5070</td>\n",
              "      <td>2006-09-29</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>NATIONAL CAPITALS</td>\n",
              "      <td>None</td>\n",
              "      <td>This city's website calls it \"the last divided...</td>\n",
              "      <td>Nicosia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216868</th>\n",
              "      <td>5195</td>\n",
              "      <td>2007-03-23</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>BESTSELLING AUTHORS</td>\n",
              "      <td>None</td>\n",
              "      <td>He had the year's bestselling novel a record 7...</td>\n",
              "      <td>John Grisham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216929</th>\n",
              "      <td>4999</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>Final Jeopardy!</td>\n",
              "      <td>HISTORIC NAMES</td>\n",
              "      <td>None</td>\n",
              "      <td>A silent movie title includes the last name of...</td>\n",
              "      <td>Grigori Alexandrovich Potemkin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3634 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Show Number  ...                           Answer\n",
              "55             4680  ...                           Icarus\n",
              "116            5957  ...                       Pocahontas\n",
              "174            3751  ...  H.J. Heinz (Heinz 57 Varieties)\n",
              "235            3673  ...                         Slovenia\n",
              "296            4931  ...                   the HMS Beagle\n",
              "...             ...  ...                              ...\n",
              "216686         3940  ...               Pittsburgh Pirates\n",
              "216746         6044  ...                           Moscow\n",
              "216807         5070  ...                          Nicosia\n",
              "216868         5195  ...                     John Grisham\n",
              "216929         4999  ...   Grigori Alexandrovich Potemkin\n",
              "\n",
              "[3634 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjK2a_FQ7vpe"
      },
      "source": [
        "#df.drop(df[df[' Value']=='None'],inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "wFM0vmEc8pa3",
        "outputId": "4abf07c2-1567-44c7-ed93-efd778b19701"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Show Number</th>\n",
              "      <th>Air Date</th>\n",
              "      <th>Round</th>\n",
              "      <th>Category</th>\n",
              "      <th>Value</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>HISTORY</td>\n",
              "      <td>$200</td>\n",
              "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
              "      <td>Copernicus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
              "      <td>$200</td>\n",
              "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
              "      <td>Jim Thorpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
              "      <td>$200</td>\n",
              "      <td>The city of Yuma in this state has a record av...</td>\n",
              "      <td>Arizona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>THE COMPANY LINE</td>\n",
              "      <td>$200</td>\n",
              "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
              "      <td>McDonald's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
              "      <td>$200</td>\n",
              "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
              "      <td>John Adams</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Show Number  ...      Answer\n",
              "0         4680  ...  Copernicus\n",
              "1         4680  ...  Jim Thorpe\n",
              "2         4680  ...     Arizona\n",
              "3         4680  ...  McDonald's\n",
              "4         4680  ...  John Adams\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "7IXpZwc87fnW",
        "outputId": "ad22f3a1-9309-4b06-9482-c82826f50d35"
      },
      "source": [
        "df[' Value'] = df[' Value'].apply(lambda x: int(0) if x=='None' else int(x.replace('$','').replace(',','')))\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Show Number</th>\n",
              "      <th>Air Date</th>\n",
              "      <th>Round</th>\n",
              "      <th>Category</th>\n",
              "      <th>Value</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>HISTORY</td>\n",
              "      <td>200</td>\n",
              "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
              "      <td>Copernicus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
              "      <td>200</td>\n",
              "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
              "      <td>Jim Thorpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
              "      <td>200</td>\n",
              "      <td>The city of Yuma in this state has a record av...</td>\n",
              "      <td>Arizona</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>THE COMPANY LINE</td>\n",
              "      <td>200</td>\n",
              "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
              "      <td>McDonald's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4680</td>\n",
              "      <td>2004-12-31</td>\n",
              "      <td>Jeopardy!</td>\n",
              "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
              "      <td>200</td>\n",
              "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
              "      <td>John Adams</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Show Number  ...      Answer\n",
              "0         4680  ...  Copernicus\n",
              "1         4680  ...  Jim Thorpe\n",
              "2         4680  ...     Arizona\n",
              "3         4680  ...  McDonald's\n",
              "4         4680  ...  John Adams\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7d0ymslDjn3",
        "outputId": "d38d29bf-7b08-48c3-d003-660d7b9d1d57"
      },
      "source": [
        "lis = df[' Value'].apply(lambda x:round(x,-(len(str(x))-1)))\r\n",
        "len(lis.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-5j1gFFKmp"
      },
      "source": [
        "from sklearn import preprocessing\r\n",
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJzCGw7nf_r2",
        "outputId": "7537dfa1-a2e9-44a7-8993-e6dfa9e3e4ed"
      },
      "source": [
        "lis.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    200\n",
              "1    200\n",
              "2    200\n",
              "3    200\n",
              "4    200\n",
              "Name:  Value, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-l634-VmDfx"
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4VgQvZ1H19V"
      },
      "source": [
        "encoder = preprocessing.LabelEncoder()\r\n",
        "encoder.fit(lis)\r\n",
        "encoded_Y = encoder.transform(lis)\r\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOVj5pgHz9uB"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU94x7AvHJtB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "b755d1b00efe487bab7f9aa2be69c013",
            "f1b86de3a3a9431c8f63d3da0b4c2ed0",
            "5b392d3c17ba47daade4f41099656559",
            "ec8dde436e2b48cc8b5eeefa7034b73d",
            "ce07fc77daa347ea8df4da3f114d52a8",
            "88690a950a384f3b93d445231b2308b0",
            "aec6d3a8303042039cba9277cf3872d2",
            "68bcfb19843d4fd595db742e0f69401a",
            "1d87d7f7a2cf47f092546c3bc5b52a0e",
            "f3bad20b4b9c40c18c8a90b514a07ea3",
            "b18d602c077f462c831f05e04ac0d541",
            "0f672d362cbf440ea8a878d22dc4b808",
            "efd361e5779f48758a8bb33cdeb71fc2",
            "d6557effeb7443de98a141ee8608acdd",
            "6507e73b475b4af892f205657fa3cd64",
            "dfe28b387c324dbc8d1ced138931f7b6",
            "555be67bd1f24b1b95157bfde8dfe6f6",
            "2a9a83b76c8a4d3d9bb02897eb4f692d",
            "1cc3688f1d124b5cbecf0c82d3be9c52",
            "1ef053eb312547e2a9f4aeeabce6d30b",
            "90e5d5c6822244eb80354bdbbfbe523f",
            "98e38f0bbbb64a8eb78e55b6fbab4441",
            "b24fc23ad8c5476a8b6c393ed27a9e9c",
            "cdeaeb02e8e54717b3e9556caaa98ac9",
            "70655e3609784ccb8f1516245da389ac",
            "a6413ae0cc104c34a9e382c7c1893c2e",
            "a81b3d881679403099d7033aef826f90",
            "d609a50fefba487fb7a944e460e8f880",
            "23127995085043a5a0c2b11798dc4d4f",
            "27aa57e092494a1b9dd67e429c3021a7",
            "74bb098ad5cb42b98b884da5911768f0",
            "a7500317d5ae4ca99d1b69e0a9bda0cc"
          ]
        },
        "outputId": "7564a4f0-4b81-4ee3-8740-96b90e11e372"
      },
      "source": [
        "embedding = TransformerDocumentEmbeddings('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b755d1b00efe487bab7f9aa2be69c013",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d87d7f7a2cf47f092546c3bc5b52a0e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "555be67bd1f24b1b95157bfde8dfe6f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70655e3609784ccb8f1516245da389ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxCru_-tj3kY"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klXMBKQpiyHr",
        "outputId": "03b5e7f3-1bff-4113-b8e3-f042ba1bba68"
      },
      "source": [
        "emb=[]\r\n",
        "for sent in tqdm(df[' Question']):\r\n",
        "    sent=Sentence(sent)\r\n",
        "    embedding.embed(sent)\r\n",
        "    emb.append(sent.get_embedding().cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 216930/216930 [53:34<00:00, 67.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CwbTVwNbwCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb915b7-0bf7-4558-f11c-9dca309f427b"
      },
      "source": [
        "emb_cat=[]\r\n",
        "for sent in tqdm(df[' Category']):\r\n",
        "    sent=Sentence(sent)\r\n",
        "    embedding.embed(sent)\r\n",
        "    emb_cat.append(sent.get_embedding().cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 216930/216930 [54:36<00:00, 66.21it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY7CTEbNGkct"
      },
      "source": [
        "embedding_df=pd.DataFrame(np.array(emb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4T-x8Trb5Fn"
      },
      "source": [
        "embedding_df_cat=pd.DataFrame(np.array(emb_cat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s4aAbvNbcDw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "370a027d-ad6f-4a4c-f43f-cc5a0934d5b3"
      },
      "source": [
        " embedding_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>728</th>\n",
              "      <th>729</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.341941</td>\n",
              "      <td>0.094924</td>\n",
              "      <td>-0.376334</td>\n",
              "      <td>0.029432</td>\n",
              "      <td>-0.276497</td>\n",
              "      <td>0.164733</td>\n",
              "      <td>0.723231</td>\n",
              "      <td>0.616560</td>\n",
              "      <td>-0.155425</td>\n",
              "      <td>-0.365753</td>\n",
              "      <td>0.181413</td>\n",
              "      <td>0.013561</td>\n",
              "      <td>-0.761738</td>\n",
              "      <td>1.123792</td>\n",
              "      <td>0.279687</td>\n",
              "      <td>-0.207188</td>\n",
              "      <td>-0.093344</td>\n",
              "      <td>0.032123</td>\n",
              "      <td>0.079666</td>\n",
              "      <td>0.199756</td>\n",
              "      <td>-0.064871</td>\n",
              "      <td>0.018790</td>\n",
              "      <td>-0.278525</td>\n",
              "      <td>-0.057766</td>\n",
              "      <td>-0.001796</td>\n",
              "      <td>-0.179324</td>\n",
              "      <td>-0.295141</td>\n",
              "      <td>-0.254966</td>\n",
              "      <td>-0.063662</td>\n",
              "      <td>-0.026565</td>\n",
              "      <td>-0.103428</td>\n",
              "      <td>0.128542</td>\n",
              "      <td>-0.170032</td>\n",
              "      <td>-0.138652</td>\n",
              "      <td>0.348651</td>\n",
              "      <td>-0.401197</td>\n",
              "      <td>0.128721</td>\n",
              "      <td>-0.105483</td>\n",
              "      <td>0.408821</td>\n",
              "      <td>0.332912</td>\n",
              "      <td>...</td>\n",
              "      <td>0.367435</td>\n",
              "      <td>-0.687445</td>\n",
              "      <td>0.098264</td>\n",
              "      <td>0.495160</td>\n",
              "      <td>0.023792</td>\n",
              "      <td>0.003927</td>\n",
              "      <td>0.663600</td>\n",
              "      <td>-0.113314</td>\n",
              "      <td>-0.379603</td>\n",
              "      <td>-0.344899</td>\n",
              "      <td>0.080211</td>\n",
              "      <td>0.237598</td>\n",
              "      <td>0.405306</td>\n",
              "      <td>-0.031805</td>\n",
              "      <td>0.058832</td>\n",
              "      <td>-0.411982</td>\n",
              "      <td>0.797835</td>\n",
              "      <td>0.381055</td>\n",
              "      <td>-0.308689</td>\n",
              "      <td>-0.496416</td>\n",
              "      <td>-0.245136</td>\n",
              "      <td>0.246067</td>\n",
              "      <td>0.060829</td>\n",
              "      <td>0.367223</td>\n",
              "      <td>-6.200170</td>\n",
              "      <td>-0.405509</td>\n",
              "      <td>-0.136438</td>\n",
              "      <td>-0.253661</td>\n",
              "      <td>0.753087</td>\n",
              "      <td>-0.171838</td>\n",
              "      <td>-0.129338</td>\n",
              "      <td>-0.308410</td>\n",
              "      <td>0.437201</td>\n",
              "      <td>-0.368672</td>\n",
              "      <td>0.362269</td>\n",
              "      <td>-0.233356</td>\n",
              "      <td>0.246225</td>\n",
              "      <td>-0.269037</td>\n",
              "      <td>0.796916</td>\n",
              "      <td>0.425276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.128507</td>\n",
              "      <td>-0.233719</td>\n",
              "      <td>-0.844783</td>\n",
              "      <td>-0.343999</td>\n",
              "      <td>-0.750437</td>\n",
              "      <td>0.255770</td>\n",
              "      <td>0.687694</td>\n",
              "      <td>0.636580</td>\n",
              "      <td>-0.419601</td>\n",
              "      <td>0.137816</td>\n",
              "      <td>-0.128318</td>\n",
              "      <td>0.116446</td>\n",
              "      <td>-0.386482</td>\n",
              "      <td>0.577727</td>\n",
              "      <td>0.169465</td>\n",
              "      <td>0.187967</td>\n",
              "      <td>-0.658935</td>\n",
              "      <td>0.520990</td>\n",
              "      <td>-0.092766</td>\n",
              "      <td>0.289116</td>\n",
              "      <td>-0.334736</td>\n",
              "      <td>-0.258896</td>\n",
              "      <td>0.155673</td>\n",
              "      <td>-0.081731</td>\n",
              "      <td>0.129470</td>\n",
              "      <td>-0.018318</td>\n",
              "      <td>-0.725917</td>\n",
              "      <td>-0.237355</td>\n",
              "      <td>-0.140279</td>\n",
              "      <td>0.308504</td>\n",
              "      <td>-0.082538</td>\n",
              "      <td>0.237471</td>\n",
              "      <td>0.087356</td>\n",
              "      <td>-0.327513</td>\n",
              "      <td>0.197785</td>\n",
              "      <td>-0.617056</td>\n",
              "      <td>0.242382</td>\n",
              "      <td>0.001840</td>\n",
              "      <td>0.207416</td>\n",
              "      <td>0.509254</td>\n",
              "      <td>...</td>\n",
              "      <td>0.722117</td>\n",
              "      <td>-0.383471</td>\n",
              "      <td>-0.241573</td>\n",
              "      <td>0.296122</td>\n",
              "      <td>-0.162941</td>\n",
              "      <td>-0.431656</td>\n",
              "      <td>0.025582</td>\n",
              "      <td>0.060476</td>\n",
              "      <td>-0.437279</td>\n",
              "      <td>-0.174386</td>\n",
              "      <td>-0.641511</td>\n",
              "      <td>0.301926</td>\n",
              "      <td>-0.190386</td>\n",
              "      <td>-0.015724</td>\n",
              "      <td>0.098245</td>\n",
              "      <td>0.041024</td>\n",
              "      <td>0.349340</td>\n",
              "      <td>0.399569</td>\n",
              "      <td>0.451256</td>\n",
              "      <td>0.261718</td>\n",
              "      <td>0.015345</td>\n",
              "      <td>-0.173037</td>\n",
              "      <td>0.771476</td>\n",
              "      <td>0.155778</td>\n",
              "      <td>-5.708577</td>\n",
              "      <td>-0.153236</td>\n",
              "      <td>-0.562304</td>\n",
              "      <td>-0.484892</td>\n",
              "      <td>0.295399</td>\n",
              "      <td>0.048172</td>\n",
              "      <td>0.531744</td>\n",
              "      <td>-0.195859</td>\n",
              "      <td>0.306699</td>\n",
              "      <td>0.312698</td>\n",
              "      <td>0.905621</td>\n",
              "      <td>0.004755</td>\n",
              "      <td>-0.589927</td>\n",
              "      <td>-0.033032</td>\n",
              "      <td>0.354681</td>\n",
              "      <td>0.643932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.094619</td>\n",
              "      <td>-0.242064</td>\n",
              "      <td>0.576521</td>\n",
              "      <td>-0.387843</td>\n",
              "      <td>-0.065934</td>\n",
              "      <td>-0.913236</td>\n",
              "      <td>0.427831</td>\n",
              "      <td>1.181923</td>\n",
              "      <td>-0.598973</td>\n",
              "      <td>-0.566863</td>\n",
              "      <td>-0.442924</td>\n",
              "      <td>-0.349443</td>\n",
              "      <td>-0.958734</td>\n",
              "      <td>0.714954</td>\n",
              "      <td>-0.526836</td>\n",
              "      <td>-0.180196</td>\n",
              "      <td>0.648143</td>\n",
              "      <td>0.967059</td>\n",
              "      <td>0.108464</td>\n",
              "      <td>0.406331</td>\n",
              "      <td>-0.095781</td>\n",
              "      <td>-0.708966</td>\n",
              "      <td>0.242528</td>\n",
              "      <td>0.394304</td>\n",
              "      <td>0.116582</td>\n",
              "      <td>-0.466965</td>\n",
              "      <td>0.256210</td>\n",
              "      <td>0.072991</td>\n",
              "      <td>0.531975</td>\n",
              "      <td>-0.053678</td>\n",
              "      <td>-0.246165</td>\n",
              "      <td>-0.199117</td>\n",
              "      <td>0.299777</td>\n",
              "      <td>-0.505421</td>\n",
              "      <td>0.401915</td>\n",
              "      <td>-0.281864</td>\n",
              "      <td>-0.002000</td>\n",
              "      <td>-0.288159</td>\n",
              "      <td>0.200616</td>\n",
              "      <td>0.503714</td>\n",
              "      <td>...</td>\n",
              "      <td>1.290082</td>\n",
              "      <td>-0.954728</td>\n",
              "      <td>0.313304</td>\n",
              "      <td>0.404931</td>\n",
              "      <td>0.658690</td>\n",
              "      <td>0.517945</td>\n",
              "      <td>0.675591</td>\n",
              "      <td>0.098386</td>\n",
              "      <td>-0.859829</td>\n",
              "      <td>0.418262</td>\n",
              "      <td>-0.659302</td>\n",
              "      <td>-0.205339</td>\n",
              "      <td>-0.929649</td>\n",
              "      <td>-0.232026</td>\n",
              "      <td>0.401901</td>\n",
              "      <td>0.062108</td>\n",
              "      <td>0.200821</td>\n",
              "      <td>0.468511</td>\n",
              "      <td>-0.640829</td>\n",
              "      <td>-0.953557</td>\n",
              "      <td>-0.441081</td>\n",
              "      <td>-0.131470</td>\n",
              "      <td>0.259628</td>\n",
              "      <td>-0.662283</td>\n",
              "      <td>-3.744334</td>\n",
              "      <td>-0.110969</td>\n",
              "      <td>-0.758636</td>\n",
              "      <td>-0.403865</td>\n",
              "      <td>-0.478761</td>\n",
              "      <td>-0.355652</td>\n",
              "      <td>0.329184</td>\n",
              "      <td>-0.189930</td>\n",
              "      <td>0.249549</td>\n",
              "      <td>-0.775645</td>\n",
              "      <td>-0.193334</td>\n",
              "      <td>0.470124</td>\n",
              "      <td>0.055535</td>\n",
              "      <td>0.206574</td>\n",
              "      <td>0.151918</td>\n",
              "      <td>0.525866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.305038</td>\n",
              "      <td>0.029787</td>\n",
              "      <td>0.092972</td>\n",
              "      <td>-0.217257</td>\n",
              "      <td>-0.084313</td>\n",
              "      <td>-0.072321</td>\n",
              "      <td>0.398166</td>\n",
              "      <td>0.841287</td>\n",
              "      <td>0.023509</td>\n",
              "      <td>-0.228974</td>\n",
              "      <td>0.437275</td>\n",
              "      <td>-0.633354</td>\n",
              "      <td>0.304974</td>\n",
              "      <td>0.783546</td>\n",
              "      <td>-0.259387</td>\n",
              "      <td>-0.066777</td>\n",
              "      <td>-0.357454</td>\n",
              "      <td>-0.105244</td>\n",
              "      <td>0.238309</td>\n",
              "      <td>-0.404650</td>\n",
              "      <td>-0.297471</td>\n",
              "      <td>-1.005919</td>\n",
              "      <td>0.374824</td>\n",
              "      <td>0.347509</td>\n",
              "      <td>-0.083939</td>\n",
              "      <td>-0.038334</td>\n",
              "      <td>-0.033184</td>\n",
              "      <td>-0.365142</td>\n",
              "      <td>-0.189619</td>\n",
              "      <td>0.327533</td>\n",
              "      <td>-0.094010</td>\n",
              "      <td>0.201667</td>\n",
              "      <td>-0.381318</td>\n",
              "      <td>-0.277377</td>\n",
              "      <td>-0.085561</td>\n",
              "      <td>-0.126885</td>\n",
              "      <td>0.393007</td>\n",
              "      <td>-0.280727</td>\n",
              "      <td>-0.181641</td>\n",
              "      <td>0.411613</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.091412</td>\n",
              "      <td>-0.416713</td>\n",
              "      <td>-0.428174</td>\n",
              "      <td>0.202310</td>\n",
              "      <td>0.251766</td>\n",
              "      <td>0.108755</td>\n",
              "      <td>0.273161</td>\n",
              "      <td>-0.299223</td>\n",
              "      <td>-0.308041</td>\n",
              "      <td>0.173473</td>\n",
              "      <td>0.170597</td>\n",
              "      <td>0.734981</td>\n",
              "      <td>0.102962</td>\n",
              "      <td>-0.124902</td>\n",
              "      <td>-0.012301</td>\n",
              "      <td>-0.255094</td>\n",
              "      <td>0.521741</td>\n",
              "      <td>-0.135504</td>\n",
              "      <td>0.069239</td>\n",
              "      <td>0.072513</td>\n",
              "      <td>0.161355</td>\n",
              "      <td>0.036282</td>\n",
              "      <td>0.458882</td>\n",
              "      <td>0.065597</td>\n",
              "      <td>-4.859316</td>\n",
              "      <td>-0.286842</td>\n",
              "      <td>0.089336</td>\n",
              "      <td>-0.134671</td>\n",
              "      <td>-0.264942</td>\n",
              "      <td>-0.085686</td>\n",
              "      <td>-0.198908</td>\n",
              "      <td>-0.025481</td>\n",
              "      <td>-0.006927</td>\n",
              "      <td>0.039658</td>\n",
              "      <td>0.070242</td>\n",
              "      <td>0.181556</td>\n",
              "      <td>-0.190494</td>\n",
              "      <td>-0.136517</td>\n",
              "      <td>0.300830</td>\n",
              "      <td>0.005864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.782578</td>\n",
              "      <td>-0.142274</td>\n",
              "      <td>-0.479551</td>\n",
              "      <td>-0.011190</td>\n",
              "      <td>0.344046</td>\n",
              "      <td>0.138570</td>\n",
              "      <td>0.558167</td>\n",
              "      <td>0.747103</td>\n",
              "      <td>-0.484472</td>\n",
              "      <td>0.118545</td>\n",
              "      <td>0.388098</td>\n",
              "      <td>0.180945</td>\n",
              "      <td>-0.196684</td>\n",
              "      <td>0.990437</td>\n",
              "      <td>0.223871</td>\n",
              "      <td>0.076892</td>\n",
              "      <td>-0.439313</td>\n",
              "      <td>0.119782</td>\n",
              "      <td>0.323696</td>\n",
              "      <td>-0.049668</td>\n",
              "      <td>-0.309857</td>\n",
              "      <td>0.103998</td>\n",
              "      <td>0.141345</td>\n",
              "      <td>-0.369422</td>\n",
              "      <td>0.026889</td>\n",
              "      <td>-0.217255</td>\n",
              "      <td>-0.449079</td>\n",
              "      <td>-0.117807</td>\n",
              "      <td>-0.235157</td>\n",
              "      <td>0.040084</td>\n",
              "      <td>-0.243649</td>\n",
              "      <td>0.338617</td>\n",
              "      <td>-0.661340</td>\n",
              "      <td>-0.169628</td>\n",
              "      <td>0.102309</td>\n",
              "      <td>-0.469218</td>\n",
              "      <td>0.744263</td>\n",
              "      <td>0.068087</td>\n",
              "      <td>0.153180</td>\n",
              "      <td>0.209375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693112</td>\n",
              "      <td>0.204081</td>\n",
              "      <td>-0.258195</td>\n",
              "      <td>0.294535</td>\n",
              "      <td>-0.457003</td>\n",
              "      <td>-0.282465</td>\n",
              "      <td>0.107284</td>\n",
              "      <td>-0.051363</td>\n",
              "      <td>0.044945</td>\n",
              "      <td>-0.257412</td>\n",
              "      <td>-0.288259</td>\n",
              "      <td>0.091015</td>\n",
              "      <td>0.377953</td>\n",
              "      <td>-0.340515</td>\n",
              "      <td>0.338883</td>\n",
              "      <td>-0.022783</td>\n",
              "      <td>0.148259</td>\n",
              "      <td>0.770075</td>\n",
              "      <td>-0.062061</td>\n",
              "      <td>-0.068802</td>\n",
              "      <td>-0.212018</td>\n",
              "      <td>-0.314953</td>\n",
              "      <td>0.454769</td>\n",
              "      <td>0.075039</td>\n",
              "      <td>-6.862163</td>\n",
              "      <td>-0.862197</td>\n",
              "      <td>-0.811817</td>\n",
              "      <td>-0.627586</td>\n",
              "      <td>0.170839</td>\n",
              "      <td>0.309395</td>\n",
              "      <td>0.156163</td>\n",
              "      <td>0.232373</td>\n",
              "      <td>-0.226632</td>\n",
              "      <td>-0.157377</td>\n",
              "      <td>0.908767</td>\n",
              "      <td>-0.071063</td>\n",
              "      <td>-0.054051</td>\n",
              "      <td>-0.247619</td>\n",
              "      <td>0.097197</td>\n",
              "      <td>0.331455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       765       766       767\n",
              "0 -0.341941  0.094924 -0.376334  ... -0.269037  0.796916  0.425276\n",
              "1 -1.128507 -0.233719 -0.844783  ... -0.033032  0.354681  0.643932\n",
              "2  0.094619 -0.242064  0.576521  ...  0.206574  0.151918  0.525866\n",
              "3 -0.305038  0.029787  0.092972  ... -0.136517  0.300830  0.005864\n",
              "4 -0.782578 -0.142274 -0.479551  ... -0.247619  0.097197  0.331455\n",
              "\n",
              "[5 rows x 768 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3PQdQn5rI4G"
      },
      "source": [
        "final_df=pd.concat([embedding_df,embedding_df_cat],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W60n157F-E4i",
        "outputId": "844bc0c8-2986-40b2-e076-22b7c980f8be"
      },
      "source": [
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216930, 1536)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqFjBl7R1cSH"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(final_df,encoded_Y,test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQq2iRbD-irZ"
      },
      "source": [
        "x_train=np.array(x_train)\r\n",
        "x_validation=np.array(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH0yiRlg2XuW",
        "outputId": "d62f768b-2c89-464e-c29e-7cebc5fa7898"
      },
      "source": [
        "#x_test=np.array(emb)\r\n",
        "x_validation=x_test\r\n",
        "x_validation.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54233, 1536)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdJ_KGEO2cDo",
        "outputId": "f7aae210-84b7-4210-d0dd-2a9be26cd1e9"
      },
      "source": [
        "y_train=np.array(y_train)\r\n",
        "y_validation=np.array(y_test)\r\n",
        "print(y_train.shape,y_validation.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(162697,) (54233,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DolCLEq15Ipx",
        "outputId": "25f58aca-d4a0-42f9-c9e2-c820d8d4381b"
      },
      "source": [
        "X_train = x_train.reshape((-1, 768*2, 1))\r\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162697, 1536, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG3oUV5B5NMs",
        "outputId": "9f8d622d-1851-4391-bdee-7c1eef6b26b9"
      },
      "source": [
        "X_test = x_validation.reshape((-1, 768*2, 1))\r\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54233, 1536, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXIm0P0Y2h9H"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Conv1D(256, 5,activation='relu'))\r\n",
        "model.add(MaxPool1D())\r\n",
        "model.add(Conv1D(180, 5,activation='relu'))\r\n",
        "model.add(MaxPool1D())\r\n",
        "model.add(Conv1D(128, 5,activation='relu'))\r\n",
        "model.add(GlobalMaxPooling1D())\r\n",
        "model.add(Dense(60, activation='relu'))\r\n",
        "model.add(Dense(24, activation='softmax'))\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-xbZOoV4OD1",
        "outputId": "88ed46ae-1968-4588-eced-a11bf1e344e8"
      },
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=200,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5085/5085 [==============================] - 69s 7ms/step - loss: 2.2371 - accuracy: 0.1883 - val_loss: 2.1739 - val_accuracy: 0.1949\n",
            "Epoch 2/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1790 - accuracy: 0.1946 - val_loss: 2.1775 - val_accuracy: 0.1949\n",
            "Epoch 3/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1773 - accuracy: 0.1945 - val_loss: 2.1707 - val_accuracy: 0.1949\n",
            "Epoch 4/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1748 - accuracy: 0.1956 - val_loss: 2.1696 - val_accuracy: 0.1949\n",
            "Epoch 5/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1718 - accuracy: 0.1944 - val_loss: 2.1697 - val_accuracy: 0.1949\n",
            "Epoch 6/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1710 - accuracy: 0.1944 - val_loss: 2.1735 - val_accuracy: 0.1949\n",
            "Epoch 7/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1683 - accuracy: 0.1955 - val_loss: 2.1699 - val_accuracy: 0.1949\n",
            "Epoch 8/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1712 - accuracy: 0.1937 - val_loss: 2.1688 - val_accuracy: 0.1949\n",
            "Epoch 9/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1679 - accuracy: 0.1943 - val_loss: 2.1694 - val_accuracy: 0.1949\n",
            "Epoch 10/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1657 - accuracy: 0.1961 - val_loss: 2.1658 - val_accuracy: 0.1949\n",
            "Epoch 11/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1677 - accuracy: 0.1958 - val_loss: 2.1672 - val_accuracy: 0.1949\n",
            "Epoch 12/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1683 - accuracy: 0.1957 - val_loss: 2.1661 - val_accuracy: 0.1949\n",
            "Epoch 13/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1655 - accuracy: 0.1953 - val_loss: 2.1694 - val_accuracy: 0.1949\n",
            "Epoch 14/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1670 - accuracy: 0.1951 - val_loss: 2.1660 - val_accuracy: 0.1950\n",
            "Epoch 15/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1690 - accuracy: 0.1959 - val_loss: 2.1668 - val_accuracy: 0.1949\n",
            "Epoch 16/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1680 - accuracy: 0.1951 - val_loss: 2.1655 - val_accuracy: 0.1949\n",
            "Epoch 17/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1690 - accuracy: 0.1945 - val_loss: 2.1653 - val_accuracy: 0.1949\n",
            "Epoch 18/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1681 - accuracy: 0.1954 - val_loss: 2.1651 - val_accuracy: 0.1949\n",
            "Epoch 19/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1657 - accuracy: 0.1941 - val_loss: 2.1711 - val_accuracy: 0.1949\n",
            "Epoch 20/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1708 - accuracy: 0.1933 - val_loss: 2.1661 - val_accuracy: 0.1949\n",
            "Epoch 21/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1665 - accuracy: 0.1944 - val_loss: 2.1666 - val_accuracy: 0.1949\n",
            "Epoch 22/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1680 - accuracy: 0.1929 - val_loss: 2.1652 - val_accuracy: 0.1949\n",
            "Epoch 23/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1678 - accuracy: 0.1940 - val_loss: 2.1664 - val_accuracy: 0.1949\n",
            "Epoch 24/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1698 - accuracy: 0.1937 - val_loss: 2.1662 - val_accuracy: 0.1949\n",
            "Epoch 25/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1680 - accuracy: 0.1948 - val_loss: 2.1656 - val_accuracy: 0.1949\n",
            "Epoch 26/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1658 - accuracy: 0.1942 - val_loss: 2.1746 - val_accuracy: 0.1949\n",
            "Epoch 27/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1653 - accuracy: 0.1951 - val_loss: 2.1649 - val_accuracy: 0.1945\n",
            "Epoch 28/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1670 - accuracy: 0.1957 - val_loss: 2.1653 - val_accuracy: 0.1949\n",
            "Epoch 29/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1684 - accuracy: 0.1941 - val_loss: 2.1657 - val_accuracy: 0.1949\n",
            "Epoch 30/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1655 - accuracy: 0.1964 - val_loss: 2.1664 - val_accuracy: 0.1949\n",
            "Epoch 31/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1653 - accuracy: 0.1952 - val_loss: 2.1644 - val_accuracy: 0.1949\n",
            "Epoch 32/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1638 - accuracy: 0.1953 - val_loss: 2.1673 - val_accuracy: 0.1949\n",
            "Epoch 33/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1689 - accuracy: 0.1950 - val_loss: 2.1655 - val_accuracy: 0.1949\n",
            "Epoch 34/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1621 - accuracy: 0.1948 - val_loss: 2.1681 - val_accuracy: 0.1949\n",
            "Epoch 35/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1678 - accuracy: 0.1959 - val_loss: 2.1652 - val_accuracy: 0.1949\n",
            "Epoch 36/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1649 - accuracy: 0.1949 - val_loss: 2.1651 - val_accuracy: 0.1949\n",
            "Epoch 37/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1650 - accuracy: 0.1935 - val_loss: 2.1669 - val_accuracy: 0.1949\n",
            "Epoch 38/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1661 - accuracy: 0.1951 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 39/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1664 - accuracy: 0.1945 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 40/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1658 - accuracy: 0.1946 - val_loss: 2.1652 - val_accuracy: 0.1949\n",
            "Epoch 41/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1661 - accuracy: 0.1944 - val_loss: 2.1654 - val_accuracy: 0.1949\n",
            "Epoch 42/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1668 - accuracy: 0.1938 - val_loss: 2.1656 - val_accuracy: 0.1949\n",
            "Epoch 43/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1658 - accuracy: 0.1958 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 44/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1657 - accuracy: 0.1950 - val_loss: 2.1684 - val_accuracy: 0.1948\n",
            "Epoch 45/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1650 - accuracy: 0.1945 - val_loss: 2.1640 - val_accuracy: 0.1951\n",
            "Epoch 46/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1644 - accuracy: 0.1950 - val_loss: 2.1666 - val_accuracy: 0.1949\n",
            "Epoch 47/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1633 - accuracy: 0.1963 - val_loss: 2.1658 - val_accuracy: 0.1949\n",
            "Epoch 48/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1656 - accuracy: 0.1941 - val_loss: 2.1659 - val_accuracy: 0.1949\n",
            "Epoch 49/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1653 - accuracy: 0.1963 - val_loss: 2.1657 - val_accuracy: 0.1949\n",
            "Epoch 50/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1635 - accuracy: 0.1946 - val_loss: 2.1655 - val_accuracy: 0.1949\n",
            "Epoch 51/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1628 - accuracy: 0.1957 - val_loss: 2.1654 - val_accuracy: 0.1950\n",
            "Epoch 52/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1640 - accuracy: 0.1962 - val_loss: 2.1647 - val_accuracy: 0.1949\n",
            "Epoch 53/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1648 - accuracy: 0.1955 - val_loss: 2.1647 - val_accuracy: 0.1949\n",
            "Epoch 54/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1670 - accuracy: 0.1941 - val_loss: 2.1654 - val_accuracy: 0.1949\n",
            "Epoch 55/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1674 - accuracy: 0.1931 - val_loss: 2.1664 - val_accuracy: 0.1949\n",
            "Epoch 56/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1653 - accuracy: 0.1945 - val_loss: 2.1660 - val_accuracy: 0.1949\n",
            "Epoch 57/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1640 - accuracy: 0.1948 - val_loss: 2.1671 - val_accuracy: 0.1949\n",
            "Epoch 58/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1635 - accuracy: 0.1952 - val_loss: 2.1670 - val_accuracy: 0.1949\n",
            "Epoch 59/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1666 - accuracy: 0.1964 - val_loss: 2.1667 - val_accuracy: 0.1949\n",
            "Epoch 60/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1651 - accuracy: 0.1944 - val_loss: 2.1657 - val_accuracy: 0.1949\n",
            "Epoch 61/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1649 - accuracy: 0.1947 - val_loss: 2.1656 - val_accuracy: 0.1949\n",
            "Epoch 62/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1672 - accuracy: 0.1950 - val_loss: 2.1690 - val_accuracy: 0.1949\n",
            "Epoch 63/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1658 - accuracy: 0.1966 - val_loss: 2.1639 - val_accuracy: 0.1949\n",
            "Epoch 64/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1617 - accuracy: 0.1938 - val_loss: 2.1655 - val_accuracy: 0.1949\n",
            "Epoch 65/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1650 - accuracy: 0.1950 - val_loss: 2.1654 - val_accuracy: 0.1949\n",
            "Epoch 66/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1657 - accuracy: 0.1945 - val_loss: 2.1695 - val_accuracy: 0.1949\n",
            "Epoch 67/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1656 - accuracy: 0.1933 - val_loss: 2.1659 - val_accuracy: 0.1949\n",
            "Epoch 68/200\n",
            "5085/5085 [==============================] - 31s 6ms/step - loss: 2.1636 - accuracy: 0.1942 - val_loss: 2.1664 - val_accuracy: 0.1948\n",
            "Epoch 69/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1632 - accuracy: 0.1958 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 70/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1653 - accuracy: 0.1946 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 71/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1662 - accuracy: 0.1936 - val_loss: 2.1665 - val_accuracy: 0.1949\n",
            "Epoch 72/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1664 - accuracy: 0.1943 - val_loss: 2.1651 - val_accuracy: 0.1949\n",
            "Epoch 73/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1656 - accuracy: 0.1955 - val_loss: 2.1669 - val_accuracy: 0.1949\n",
            "Epoch 74/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1637 - accuracy: 0.1959 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 75/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1646 - accuracy: 0.1944 - val_loss: 2.1648 - val_accuracy: 0.1949\n",
            "Epoch 76/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1652 - accuracy: 0.1952 - val_loss: 2.1645 - val_accuracy: 0.1949\n",
            "Epoch 77/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1631 - accuracy: 0.1941 - val_loss: 2.1649 - val_accuracy: 0.1949\n",
            "Epoch 78/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1641 - accuracy: 0.1949 - val_loss: 2.1665 - val_accuracy: 0.1940\n",
            "Epoch 79/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1649 - accuracy: 0.1935 - val_loss: 2.1653 - val_accuracy: 0.1949\n",
            "Epoch 80/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1607 - accuracy: 0.1957 - val_loss: 2.1669 - val_accuracy: 0.1948\n",
            "Epoch 81/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1652 - accuracy: 0.1947 - val_loss: 2.1681 - val_accuracy: 0.1949\n",
            "Epoch 82/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1657 - accuracy: 0.1936 - val_loss: 2.1683 - val_accuracy: 0.1946\n",
            "Epoch 83/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1632 - accuracy: 0.1942 - val_loss: 2.1645 - val_accuracy: 0.1949\n",
            "Epoch 84/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1651 - accuracy: 0.1939 - val_loss: 2.1663 - val_accuracy: 0.1949\n",
            "Epoch 85/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1632 - accuracy: 0.1953 - val_loss: 2.1657 - val_accuracy: 0.1949\n",
            "Epoch 86/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1647 - accuracy: 0.1933 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 87/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1623 - accuracy: 0.1945 - val_loss: 2.1645 - val_accuracy: 0.1949\n",
            "Epoch 88/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1616 - accuracy: 0.1953 - val_loss: 2.1642 - val_accuracy: 0.1949\n",
            "Epoch 89/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1648 - accuracy: 0.1947 - val_loss: 2.1700 - val_accuracy: 0.1949\n",
            "Epoch 90/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1672 - accuracy: 0.1940 - val_loss: 2.1651 - val_accuracy: 0.1949\n",
            "Epoch 91/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1636 - accuracy: 0.1953 - val_loss: 2.1688 - val_accuracy: 0.1949\n",
            "Epoch 92/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1653 - accuracy: 0.1954 - val_loss: 2.1656 - val_accuracy: 0.1949\n",
            "Epoch 93/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1673 - accuracy: 0.1950 - val_loss: 2.1676 - val_accuracy: 0.1948\n",
            "Epoch 94/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1638 - accuracy: 0.1947 - val_loss: 2.1650 - val_accuracy: 0.1949\n",
            "Epoch 95/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1639 - accuracy: 0.1931 - val_loss: 2.1648 - val_accuracy: 0.1949\n",
            "Epoch 96/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1644 - accuracy: 0.1951 - val_loss: 2.1674 - val_accuracy: 0.1948\n",
            "Epoch 97/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1642 - accuracy: 0.1957 - val_loss: 2.1653 - val_accuracy: 0.1949\n",
            "Epoch 98/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1643 - accuracy: 0.1957 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 99/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1669 - accuracy: 0.1948 - val_loss: 2.1673 - val_accuracy: 0.1885\n",
            "Epoch 100/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1641 - accuracy: 0.1951 - val_loss: 2.1666 - val_accuracy: 0.1948\n",
            "Epoch 101/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1666 - accuracy: 0.1945 - val_loss: 2.1651 - val_accuracy: 0.1949\n",
            "Epoch 102/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1624 - accuracy: 0.1945 - val_loss: 2.1672 - val_accuracy: 0.1949\n",
            "Epoch 103/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1644 - accuracy: 0.1940 - val_loss: 2.1724 - val_accuracy: 0.1949\n",
            "Epoch 104/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1677 - accuracy: 0.1951 - val_loss: 2.1660 - val_accuracy: 0.1949\n",
            "Epoch 105/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1645 - accuracy: 0.1943 - val_loss: 2.1695 - val_accuracy: 0.1949\n",
            "Epoch 106/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1681 - accuracy: 0.1951 - val_loss: 2.1683 - val_accuracy: 0.1949\n",
            "Epoch 107/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1679 - accuracy: 0.1944 - val_loss: 2.1683 - val_accuracy: 0.1949\n",
            "Epoch 108/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1658 - accuracy: 0.1945 - val_loss: 2.1677 - val_accuracy: 0.1950\n",
            "Epoch 109/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1643 - accuracy: 0.1960 - val_loss: 2.1685 - val_accuracy: 0.1951\n",
            "Epoch 110/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1654 - accuracy: 0.1954 - val_loss: 2.1677 - val_accuracy: 0.1949\n",
            "Epoch 111/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1661 - accuracy: 0.1950 - val_loss: 2.1757 - val_accuracy: 0.1950\n",
            "Epoch 112/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1667 - accuracy: 0.1939 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 113/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1648 - accuracy: 0.1944 - val_loss: 2.1695 - val_accuracy: 0.1949\n",
            "Epoch 114/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1649 - accuracy: 0.1960 - val_loss: 2.1707 - val_accuracy: 0.1949\n",
            "Epoch 115/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1673 - accuracy: 0.1937 - val_loss: 2.1682 - val_accuracy: 0.1949\n",
            "Epoch 116/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1684 - accuracy: 0.1937 - val_loss: 2.1690 - val_accuracy: 0.1949\n",
            "Epoch 117/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1674 - accuracy: 0.1934 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 118/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1656 - accuracy: 0.1937 - val_loss: 2.1698 - val_accuracy: 0.1949\n",
            "Epoch 119/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1651 - accuracy: 0.1964 - val_loss: 2.1677 - val_accuracy: 0.1949\n",
            "Epoch 120/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1665 - accuracy: 0.1956 - val_loss: 2.1690 - val_accuracy: 0.1949\n",
            "Epoch 121/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1685 - accuracy: 0.1951 - val_loss: 2.1676 - val_accuracy: 0.1949\n",
            "Epoch 122/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1671 - accuracy: 0.1937 - val_loss: 2.1688 - val_accuracy: 0.1915\n",
            "Epoch 123/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1676 - accuracy: 0.1950 - val_loss: 2.1672 - val_accuracy: 0.1949\n",
            "Epoch 124/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1662 - accuracy: 0.1952 - val_loss: 2.1671 - val_accuracy: 0.1949\n",
            "Epoch 125/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1659 - accuracy: 0.1951 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 126/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1654 - accuracy: 0.1944 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 127/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1644 - accuracy: 0.1941 - val_loss: 2.1669 - val_accuracy: 0.1949\n",
            "Epoch 128/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1657 - accuracy: 0.1932 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 129/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1651 - accuracy: 0.1953 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 130/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1699 - accuracy: 0.1939 - val_loss: 2.1671 - val_accuracy: 0.1950\n",
            "Epoch 131/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1653 - accuracy: 0.1955 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 132/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1674 - accuracy: 0.1939 - val_loss: 2.1678 - val_accuracy: 0.1949\n",
            "Epoch 133/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1661 - accuracy: 0.1947 - val_loss: 2.1679 - val_accuracy: 0.1949\n",
            "Epoch 134/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1666 - accuracy: 0.1953 - val_loss: 2.1691 - val_accuracy: 0.1949\n",
            "Epoch 135/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1665 - accuracy: 0.1936 - val_loss: 2.1688 - val_accuracy: 0.1949\n",
            "Epoch 136/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1666 - accuracy: 0.1946 - val_loss: 2.1707 - val_accuracy: 0.1950\n",
            "Epoch 137/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1676 - accuracy: 0.1928 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 138/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1657 - accuracy: 0.1952 - val_loss: 2.1671 - val_accuracy: 0.1949\n",
            "Epoch 139/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1660 - accuracy: 0.1957 - val_loss: 2.1673 - val_accuracy: 0.1947\n",
            "Epoch 140/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1673 - accuracy: 0.1963 - val_loss: 2.1671 - val_accuracy: 0.1949\n",
            "Epoch 141/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1663 - accuracy: 0.1949 - val_loss: 2.1695 - val_accuracy: 0.1949\n",
            "Epoch 142/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1640 - accuracy: 0.1938 - val_loss: 2.1698 - val_accuracy: 0.1949\n",
            "Epoch 143/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1676 - accuracy: 0.1946 - val_loss: 2.1673 - val_accuracy: 0.1949\n",
            "Epoch 144/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1686 - accuracy: 0.1967 - val_loss: 2.1715 - val_accuracy: 0.1929\n",
            "Epoch 145/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1650 - accuracy: 0.1925 - val_loss: 2.1749 - val_accuracy: 0.1949\n",
            "Epoch 146/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1693 - accuracy: 0.1932 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 147/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1670 - accuracy: 0.1945 - val_loss: 2.1695 - val_accuracy: 0.1949\n",
            "Epoch 148/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1664 - accuracy: 0.1950 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 149/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1660 - accuracy: 0.1954 - val_loss: 2.1686 - val_accuracy: 0.1949\n",
            "Epoch 150/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1638 - accuracy: 0.1953 - val_loss: 2.1679 - val_accuracy: 0.1949\n",
            "Epoch 151/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1674 - accuracy: 0.1955 - val_loss: 2.1678 - val_accuracy: 0.1949\n",
            "Epoch 152/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1651 - accuracy: 0.1949 - val_loss: 2.1708 - val_accuracy: 0.1949\n",
            "Epoch 153/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1678 - accuracy: 0.1945 - val_loss: 2.1730 - val_accuracy: 0.1949\n",
            "Epoch 154/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1665 - accuracy: 0.1937 - val_loss: 2.1670 - val_accuracy: 0.1949\n",
            "Epoch 155/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1634 - accuracy: 0.1939 - val_loss: 2.1670 - val_accuracy: 0.1949\n",
            "Epoch 156/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1674 - accuracy: 0.1966 - val_loss: 2.1676 - val_accuracy: 0.1949\n",
            "Epoch 157/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1656 - accuracy: 0.1933 - val_loss: 2.1670 - val_accuracy: 0.1949\n",
            "Epoch 158/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1652 - accuracy: 0.1953 - val_loss: 2.1691 - val_accuracy: 0.1949\n",
            "Epoch 159/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1689 - accuracy: 0.1958 - val_loss: 2.1724 - val_accuracy: 0.1831\n",
            "Epoch 160/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1666 - accuracy: 0.1929 - val_loss: 2.1675 - val_accuracy: 0.1951\n",
            "Epoch 161/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1650 - accuracy: 0.1955 - val_loss: 2.1689 - val_accuracy: 0.1950\n",
            "Epoch 162/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1670 - accuracy: 0.1945 - val_loss: 2.1676 - val_accuracy: 0.1949\n",
            "Epoch 163/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1628 - accuracy: 0.1958 - val_loss: 2.1672 - val_accuracy: 0.1949\n",
            "Epoch 164/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1668 - accuracy: 0.1933 - val_loss: 2.1679 - val_accuracy: 0.1949\n",
            "Epoch 165/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1659 - accuracy: 0.1946 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 166/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1665 - accuracy: 0.1955 - val_loss: 2.1686 - val_accuracy: 0.1942\n",
            "Epoch 167/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1624 - accuracy: 0.1940 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 168/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1678 - accuracy: 0.1927 - val_loss: 2.1681 - val_accuracy: 0.1952\n",
            "Epoch 169/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1667 - accuracy: 0.1948 - val_loss: 2.1682 - val_accuracy: 0.1949\n",
            "Epoch 170/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1645 - accuracy: 0.1941 - val_loss: 2.1693 - val_accuracy: 0.1949\n",
            "Epoch 171/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1663 - accuracy: 0.1947 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 172/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1675 - accuracy: 0.1938 - val_loss: 2.1672 - val_accuracy: 0.1949\n",
            "Epoch 173/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1672 - accuracy: 0.1958 - val_loss: 2.1680 - val_accuracy: 0.1949\n",
            "Epoch 174/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1681 - accuracy: 0.1931 - val_loss: 2.1726 - val_accuracy: 0.1949\n",
            "Epoch 175/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1641 - accuracy: 0.1953 - val_loss: 2.1680 - val_accuracy: 0.1949\n",
            "Epoch 176/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1681 - accuracy: 0.1931 - val_loss: 2.1677 - val_accuracy: 0.1949\n",
            "Epoch 177/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1668 - accuracy: 0.1926 - val_loss: 2.1678 - val_accuracy: 0.1949\n",
            "Epoch 178/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1632 - accuracy: 0.1952 - val_loss: 2.1801 - val_accuracy: 0.1949\n",
            "Epoch 179/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1712 - accuracy: 0.1951 - val_loss: 2.1681 - val_accuracy: 0.1949\n",
            "Epoch 180/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1653 - accuracy: 0.1949 - val_loss: 2.1695 - val_accuracy: 0.1949\n",
            "Epoch 181/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1636 - accuracy: 0.1952 - val_loss: 2.1702 - val_accuracy: 0.1948\n",
            "Epoch 182/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1692 - accuracy: 0.1929 - val_loss: 2.1672 - val_accuracy: 0.1949\n",
            "Epoch 183/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1669 - accuracy: 0.1948 - val_loss: 2.1676 - val_accuracy: 0.1949\n",
            "Epoch 184/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1662 - accuracy: 0.1934 - val_loss: 2.1684 - val_accuracy: 0.1949\n",
            "Epoch 185/200\n",
            "5085/5085 [==============================] - 33s 6ms/step - loss: 2.1692 - accuracy: 0.1942 - val_loss: 2.1733 - val_accuracy: 0.1949\n",
            "Epoch 186/200\n",
            "5085/5085 [==============================] - 33s 6ms/step - loss: 2.1673 - accuracy: 0.1955 - val_loss: 2.1674 - val_accuracy: 0.1949\n",
            "Epoch 187/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1669 - accuracy: 0.1949 - val_loss: 2.1702 - val_accuracy: 0.1949\n",
            "Epoch 188/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1658 - accuracy: 0.1978 - val_loss: 2.1688 - val_accuracy: 0.1949\n",
            "Epoch 189/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1622 - accuracy: 0.1955 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 190/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1674 - accuracy: 0.1922 - val_loss: 2.1676 - val_accuracy: 0.1949\n",
            "Epoch 191/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1673 - accuracy: 0.1940 - val_loss: 2.1690 - val_accuracy: 0.1949\n",
            "Epoch 192/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1673 - accuracy: 0.1931 - val_loss: 2.1691 - val_accuracy: 0.1949\n",
            "Epoch 193/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1666 - accuracy: 0.1958 - val_loss: 2.1700 - val_accuracy: 0.1949\n",
            "Epoch 194/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1724 - accuracy: 0.1945 - val_loss: 2.1686 - val_accuracy: 0.1949\n",
            "Epoch 195/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1671 - accuracy: 0.1943 - val_loss: 2.1679 - val_accuracy: 0.1949\n",
            "Epoch 196/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1669 - accuracy: 0.1926 - val_loss: 2.1694 - val_accuracy: 0.1949\n",
            "Epoch 197/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1627 - accuracy: 0.1962 - val_loss: 2.1675 - val_accuracy: 0.1949\n",
            "Epoch 198/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1655 - accuracy: 0.1944 - val_loss: 2.1686 - val_accuracy: 0.1949\n",
            "Epoch 199/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1674 - accuracy: 0.1934 - val_loss: 2.1771 - val_accuracy: 0.1949\n",
            "Epoch 200/200\n",
            "5085/5085 [==============================] - 32s 6ms/step - loss: 2.1753 - accuracy: 0.1942 - val_loss: 2.1677 - val_accuracy: 0.1949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45513eca10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmP6qn1bRYtY"
      },
      "source": [
        "model.save('jeo.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6QW4N12Wra3x",
        "outputId": "a9fe0616-b116-4f35-c972-33d5c6e16cd9"
      },
      "source": [
        "df[' Question'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j84nB3Wpt5Gp",
        "outputId": "299e9fb2-f5ce-4a97-fa1a-04587347f054"
      },
      "source": [
        "df[' Category'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'HISTORY'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KrPYCvrrXYf",
        "outputId": "75a76178-40a0-41b3-fbaa-c42484c36772"
      },
      "source": [
        "sent=\"For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory\"\r\n",
        "sent=Sentence(sent)\r\n",
        "embedding.embed(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence: \"For the last 8 years of his life , Galileo was under house arrest for espousing this man 's theory\"   [− Tokens: 20]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEOAkWKpt_s_",
        "outputId": "81211b21-4822-4f49-a86a-765eb473e319"
      },
      "source": [
        "sent1=\"HISTORY\"\r\n",
        "sent1=Sentence(sent1)\r\n",
        "embedding.embed(sent1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence: \"HISTORY\"   [− Tokens: 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OstvsYEuP2l"
      },
      "source": [
        "emb_q=pd.DataFrame(sent.get_embedding().cpu().detach().numpy().reshape((1,768)))\r\n",
        "emb_c=pd.DataFrame(sent1.get_embedding().cpu().detach().numpy().reshape((1,768)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWvj8WVOvO4_"
      },
      "source": [
        "final = pd.concat([emb_q,emb_c],axis=1)\r\n",
        "final = np.array(final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKvgSrjxve3G",
        "outputId": "cec06614-ee9d-4c3a-8b3b-f0a2462ff186"
      },
      "source": [
        "final=final.reshape((1,1536,-1))\r\n",
        "final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1536, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXY-bWJ5rzDa"
      },
      "source": [
        "pre=model.predict(final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TKXHCtmsBdZ",
        "outputId": "798be797-eb38-409b-86e3-bcda70d26ca3"
      },
      "source": [
        "encoder.inverse_transform([((pre)[0]).argmax()])[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdlV0xMCwA3L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}